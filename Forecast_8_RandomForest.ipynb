{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    mean_absolute_scaled_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions\n",
    "1. train/test split y (to prevent data leak)\n",
    "3. transform y with STL\n",
    "1. join X & y\n",
    "4. scale X & y\n",
    "5. train/grid-search\n",
    "6. predict & score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(y, X, horizon):\n",
    "    y.index.freq='D'\n",
    "\n",
    "    # split\n",
    "    y_train, y_test = train_test_split(y, test_size=horizon, shuffle=False)\n",
    "\n",
    "    # deseasonalize & detrend\n",
    "    transformer = make_pipeline(Deseasonalizer(sp=7), Detrender())\n",
    "    y_train_trans = transformer.fit_transform(y_train)\n",
    "    y_train_trans.name = y.name\n",
    "    y_test_trans = transformer.transform(y_test)\n",
    "    y_test_trans.name = y.name\n",
    "    y_trans = pd.concat([y_train_trans, y_test_trans])\n",
    "\n",
    "    # join\n",
    "    df = X.join(y_trans).dropna()\n",
    "    \n",
    "    # extract exo. variables from date index\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['weekofyear'] = df.index.isocalendar()['week']\n",
    "    df['month'] = df.index.month\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['year'] = df.index.year\n",
    "\n",
    "    # rolling mean\n",
    "    df['rolling_mean_2'] = df['sales'].rolling(2).mean()\n",
    "    df['rolling_mean_3'] = df['sales'].rolling(3).mean()\n",
    "    df['rolling_mean_4'] = df['sales'].rolling(4).mean()\n",
    "    df['rolling_mean_5'] = df['sales'].rolling(5).mean()\n",
    "    df['rolling_mean_6'] = df['sales'].rolling(6).mean()\n",
    "    df['rolling_mean_7'] = df['sales'].rolling(7).mean()\n",
    "\n",
    "    # expanding mean\n",
    "    # df['expanding_mean'] = df['sales'].expanding(2).mean()\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df, transformer\n",
    "\n",
    "\n",
    "# CV \n",
    "def cross_validation_result(data, tuned_model, model_name, transformer, horizon, rolls=4):\n",
    "    # score model with CV on store data\n",
    "    mae_CVs = []\n",
    "    rmse_CVs = []\n",
    "    mape_CVs = []\n",
    "    mase_CVs = []\n",
    "    for i in range(rolls):\n",
    "        # print(f\"fold {i}---------------\")\n",
    "        \n",
    "        # split data\n",
    "        y_train = data.iloc[: -(rolls - i) * horizon]\n",
    "        y_test = data.iloc[\n",
    "            np.r_[-(rolls - i) * horizon : -(rolls - i - 1) * horizon]]\n",
    "\n",
    "        # fit model\n",
    "        model = tuned_model\n",
    "        model.fit(\n",
    "            y    = y_train['sales'],\n",
    "            exog = y_train[y_train.columns.difference(['sales'])]\n",
    "        )\n",
    "        \n",
    "        # make forecast\n",
    "        y_hat = model.predict(\n",
    "                        steps = horizon,\n",
    "                        exog = y_test[y_test.columns.difference(['sales'])]\n",
    "                    )\n",
    "        y_hat = pd.Series(data=y_hat, index=y_test.index)\n",
    "        \n",
    "        # inverse\n",
    "        y_train = transformer.inverse_transform(y_train['sales'])\n",
    "        y_test = transformer.inverse_transform(y_test['sales'])\n",
    "        y_hat = transformer.inverse_transform(y_hat)\n",
    "                \n",
    "        # score\n",
    "        mae_CVs.append(round(mean_absolute_error(y_test, y_hat), 3))\n",
    "        rmse_CVs.append(round(mean_squared_error(y_test, y_hat, square_root=True), 3))\n",
    "        mape_CVs.append(round(mean_absolute_percentage_error(y_test, y_hat), 3))\n",
    "        mase_CVs.append(round(mean_absolute_scaled_error(y_test, y_hat, y_train=y_train), 3))\n",
    "        \n",
    "    return {'store':model_name,\n",
    "        'mae_RF':np.mean(mae_CVs),\n",
    "        'rmse_RF':np.mean(rmse_CVs),\n",
    "        'mape_RF':np.mean(mape_CVs),\n",
    "        'mase_RF':np.mean(mase_CVs),\n",
    "        'fc_RF':y_hat,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store = pd.read_pickle(\"data/df_daily.pkl\")\n",
    "df_store['sales'] = df_store['sales']/1e6\n",
    "df_exog = pd.read_pickle(\"data/df_exog.pkl\")\n",
    "ts_company = df_store.groupby(\"date\").sum()[\"sales\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizon = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune on company data\n",
    "grid search\n",
    "- fit once per param set on train set\n",
    "- predict & score on test set (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:77: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  if hasattr(x, \"freqstr\"):\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:78: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  if x.freqstr is None:\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:80: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  elif \"-\" in x.freqstr:\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:83: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  return x.freqstr\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:40: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  return pd.Int64Index([d.n / count for d in duration])\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:77: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  if hasattr(x, \"freqstr\"):\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:78: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  if x.freqstr is None:\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:80: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  elif \"-\" in x.freqstr:\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:83: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  return x.freqstr\n",
      "/Users/giangphan23/OneDrive - Norges Handelshøyskole/Thesis/Sales_forecast/ap8venv/lib/python3.8/site-packages/sktime/utils/datetime.py:40: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  return pd.Int64Index([d.n / count for d in duration])\n"
     ]
    }
   ],
   "source": [
    "horizon = 7\n",
    "\n",
    "# data\n",
    "df, transformer = preprocessing(ts_company, df_exog, horizon)\n",
    "\n",
    "# Grid search hyperparameters and lags\n",
    "from sklearn.preprocessing import Normalizer\n",
    "pipe = make_pipeline(\n",
    "    Normalizer(), \n",
    "    RandomForestRegressor(random_state=123)\n",
    "    )\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=pipe, \n",
    "    lags=10  # This value will be replaced in the grid search\n",
    "    )\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'randomforestregressor__max_depth': [100],#10, 50, 100],\n",
    "    'randomforestregressor__max_features': ['auto'],#, 'sqrt'],\n",
    "    'randomforestregressor__min_samples_leaf': [1],#, 2, 4],\n",
    "    'randomforestregressor__min_samples_split': [5],#],#2, 5, 10],\n",
    "    'randomforestregressor__n_estimators': [800],#200, 800, 2000]\n",
    "    }\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [7]\n",
    "\n",
    "# Grid search\n",
    "results_grid = grid_search_forecaster(\n",
    "    y=df[\"sales\"],\n",
    "    initial_train_size=len(df) - horizon,\n",
    "    exog=df[df.columns.difference([\"sales\"])],\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=horizon,\n",
    "    refit=True,\n",
    "    metric=\"mean_absolute_percentage_error\",\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "# Save model\n",
    "# dump(forecaster, filename='results/f8/RF_forecaster_7.py')\n",
    "\n",
    "# Load model\n",
    "forecaster = load('results/f8/RF_forecaster_7.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing stores 307222...\n",
      "processing stores 307244...\n",
      "processing stores 307248...\n",
      "processing stores 320264...\n"
     ]
    }
   ],
   "source": [
    "all_stores_result_CV = []\n",
    "rolls = 4\n",
    "# for store in df_store[\"store_id\"].unique():\n",
    "for store in df_store[\"store_id\"].unique()[:4]:\n",
    "    print(f\"processing stores {store}...\")\n",
    "    model_name = \"store_\" + str(store)\n",
    "\n",
    "    # data\n",
    "    ts_1_store = df_store[df_store[\"store_id\"] == store].set_index(\"date\")[\"sales\"]\n",
    "    df_1_store_pro, transformer = preprocessing(\n",
    "        ts_1_store, df_exog, horizon=horizon * rolls\n",
    "    )\n",
    "\n",
    "    # CV\n",
    "    cv_score = cross_validation_result(\n",
    "        df_1_store_pro, forecaster, model_name, transformer, horizon\n",
    "    )\n",
    "\n",
    "    # result\n",
    "    all_stores_result_CV.append(cv_score)\n",
    "all_stores_result_CV = pd.DataFrame(all_stores_result_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mae_RF     2.243375\n",
       "rmse_RF    3.184312\n",
       "mape_RF    0.113125\n",
       "mase_RF    0.283500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stores_result_CV.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mae_RF     2.228063\n",
       "rmse_RF    3.166375\n",
       "mape_RF    0.112813\n",
       "mase_RF    0.281312\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_stores_result_CV.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rolling_mean_2</td>\n",
       "      <td>0.799138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lag_1</td>\n",
       "      <td>0.077854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>expanding_mean</td>\n",
       "      <td>0.074942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lag_2</td>\n",
       "      <td>0.006483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>promo_day</td>\n",
       "      <td>0.006076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dayofweek</td>\n",
       "      <td>0.005420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lag_4</td>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rolling_mean_3</td>\n",
       "      <td>0.003503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lag_7</td>\n",
       "      <td>0.002576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lag_5</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rolling_mean_4</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>quarter</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rolling_mean_7</td>\n",
       "      <td>0.001641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lag_6</td>\n",
       "      <td>0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>year</td>\n",
       "      <td>0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rolling_mean_6</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lag_3</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rolling_mean_5</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>month</td>\n",
       "      <td>0.001411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dayofyear</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dayofmonth</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>weekofyear</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>off_day</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance\n",
       "15  rolling_mean_2    0.799138\n",
       "0            lag_1    0.077854\n",
       "10  expanding_mean    0.074942\n",
       "1            lag_2    0.006483\n",
       "13       promo_day    0.006076\n",
       "8        dayofweek    0.005420\n",
       "3            lag_4    0.003773\n",
       "16  rolling_mean_3    0.003503\n",
       "6            lag_7    0.002576\n",
       "4            lag_5    0.002192\n",
       "17  rolling_mean_4    0.002135\n",
       "14         quarter    0.002114\n",
       "20  rolling_mean_7    0.001641\n",
       "5            lag_6    0.001617\n",
       "22            year    0.001599\n",
       "19  rolling_mean_6    0.001541\n",
       "2            lag_3    0.001454\n",
       "18  rolling_mean_5    0.001425\n",
       "11           month    0.001411\n",
       "9        dayofyear    0.001187\n",
       "7       dayofmonth    0.000952\n",
       "21      weekofyear    0.000863\n",
       "12         off_day    0.000106"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.get_feature_importance().sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_stores_result_CV.to_pickle('results/f8/RF_result_7.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizon = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune on company data\n",
    "grid search\n",
    "- fit once per param set on train set\n",
    "- predict & score on test set (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|█████████████████████████████████████| 1/1 [51:49<00:00, 3109.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6 7] \n",
      "  Parameters: {'randomforestregressor__max_depth': 100, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 200}\n",
      "  Backtesting metric: 0.22167603625811044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 14\n",
    "\n",
    "# data\n",
    "df_company, transformer = preprocessing(ts_company, df_exog, horizon)\n",
    "\n",
    "# Grid search hyperparameters and lags\n",
    "from sklearn.preprocessing import Normalizer\n",
    "pipe = make_pipeline(\n",
    "    Normalizer(), \n",
    "    RandomForestRegressor(random_state=123)\n",
    "    )\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=pipe, \n",
    "    lags=10  # This value will be replaced in the grid search\n",
    "    )\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'randomforestregressor__max_depth': [100, 10, 50, 100],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt'],\n",
    "    'randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestregressor__min_samples_split': [2, 5, 10],\n",
    "    'randomforestregressor__n_estimators': [100, 200, 800, 2000]\n",
    "    }\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [7]\n",
    "\n",
    "# Grid search\n",
    "results_grid = grid_search_forecaster(\n",
    "    y=df_company[\"sales\"],\n",
    "    initial_train_size=len(df_company) - horizon,\n",
    "    exog=df_company[df_company.columns.difference([\"sales\"])],\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=horizon,\n",
    "    refit=True,\n",
    "    metric=\"mean_absolute_percentage_error\",\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# from joblib import dump, load\n",
    "# dump(forecaster, filename='results/f8/RF_forecaster_14.py')\n",
    "\n",
    "# # Load model\n",
    "# forecaster = load('results/f8/RF_forecaster_14.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2021-01-25    141.094374\n",
       "2021-01-26    203.304939\n",
       "2021-01-27    133.004034\n",
       "2021-01-28    177.037215\n",
       "2021-01-29    189.516012\n",
       "2021-01-30    411.217959\n",
       "2021-01-31    816.393535\n",
       "Freq: D, Name: y, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.last_window\n",
    "# forecaster.exog_col_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_day</th>\n",
       "      <th>promo_day</th>\n",
       "      <th>sales</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>year</th>\n",
       "      <th>rolling_mean_2</th>\n",
       "      <th>rolling_mean_3</th>\n",
       "      <th>rolling_mean_4</th>\n",
       "      <th>rolling_mean_5</th>\n",
       "      <th>rolling_mean_6</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-11-19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>813.375525</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>323</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>1288.146506</td>\n",
       "      <td>1524.261493</td>\n",
       "      <td>2006.812461</td>\n",
       "      <td>1583.452202</td>\n",
       "      <td>1313.360974</td>\n",
       "      <td>1123.501059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>812.380174</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>119</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>702.717049</td>\n",
       "      <td>710.849244</td>\n",
       "      <td>680.831651</td>\n",
       "      <td>676.914212</td>\n",
       "      <td>639.537810</td>\n",
       "      <td>603.823440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>808.911958</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>173</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>742.714563</td>\n",
       "      <td>699.215118</td>\n",
       "      <td>481.050698</td>\n",
       "      <td>351.949520</td>\n",
       "      <td>263.695518</td>\n",
       "      <td>198.278268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>818.159063</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>263</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>753.091294</td>\n",
       "      <td>403.298884</td>\n",
       "      <td>262.973428</td>\n",
       "      <td>181.558576</td>\n",
       "      <td>114.304427</td>\n",
       "      <td>69.336985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            off_day  promo_day       sales  dayofweek  dayofmonth  dayofyear  \\\n",
       "date                                                                           \n",
       "2018-11-19        0          1  813.375525          0          19        323   \n",
       "2019-04-29        0          1  812.380174          0          29        119   \n",
       "2020-06-21        0          0  808.911958          6          21        173   \n",
       "2020-09-19        0          0  818.159063          5          19        263   \n",
       "\n",
       "            weekofyear  month  quarter  year  rolling_mean_2  rolling_mean_3  \\\n",
       "date                                                                           \n",
       "2018-11-19          47     11        4  2018     1288.146506     1524.261493   \n",
       "2019-04-29          18      4        2  2019      702.717049      710.849244   \n",
       "2020-06-21          25      6        2  2020      742.714563      699.215118   \n",
       "2020-09-19          38      9        3  2020      753.091294      403.298884   \n",
       "\n",
       "            rolling_mean_4  rolling_mean_5  rolling_mean_6  rolling_mean_7  \n",
       "date                                                                        \n",
       "2018-11-19     2006.812461     1583.452202     1313.360974     1123.501059  \n",
       "2019-04-29      680.831651      676.914212      639.537810      603.823440  \n",
       "2020-06-21      481.050698      351.949520      263.695518      198.278268  \n",
       "2020-09-19      262.973428      181.558576      114.304427       69.336985  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id = np.where((df[\"sales\"].values >= 800) & (df[\"sales\"].values < 820))\n",
    "# df.iloc[id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_day</th>\n",
       "      <th>promo_day</th>\n",
       "      <th>sales</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>year</th>\n",
       "      <th>rolling_mean_2</th>\n",
       "      <th>rolling_mean_3</th>\n",
       "      <th>rolling_mean_4</th>\n",
       "      <th>rolling_mean_5</th>\n",
       "      <th>rolling_mean_6</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "      <td>1268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.127760</td>\n",
       "      <td>6.463512</td>\n",
       "      <td>3.002366</td>\n",
       "      <td>15.835174</td>\n",
       "      <td>191.515773</td>\n",
       "      <td>27.887224</td>\n",
       "      <td>6.792587</td>\n",
       "      <td>2.598580</td>\n",
       "      <td>2018.827287</td>\n",
       "      <td>5.932806</td>\n",
       "      <td>5.532582</td>\n",
       "      <td>5.236885</td>\n",
       "      <td>4.988671</td>\n",
       "      <td>4.769183</td>\n",
       "      <td>4.559066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.127672</td>\n",
       "      <td>0.333954</td>\n",
       "      <td>392.648113</td>\n",
       "      <td>2.001774</td>\n",
       "      <td>8.801438</td>\n",
       "      <td>108.689397</td>\n",
       "      <td>15.518832</td>\n",
       "      <td>3.556118</td>\n",
       "      <td>1.139337</td>\n",
       "      <td>1.044086</td>\n",
       "      <td>366.189085</td>\n",
       "      <td>348.306515</td>\n",
       "      <td>332.858127</td>\n",
       "      <td>320.236176</td>\n",
       "      <td>309.933254</td>\n",
       "      <td>301.469081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-797.642367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>-746.432061</td>\n",
       "      <td>-697.223656</td>\n",
       "      <td>-633.517260</td>\n",
       "      <td>-597.246105</td>\n",
       "      <td>-563.522146</td>\n",
       "      <td>-538.397212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-182.014248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-178.065022</td>\n",
       "      <td>-171.861408</td>\n",
       "      <td>-169.020787</td>\n",
       "      <td>-161.825946</td>\n",
       "      <td>-155.808104</td>\n",
       "      <td>-155.055750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-76.457893</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>201.500000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>-73.052742</td>\n",
       "      <td>-73.659816</td>\n",
       "      <td>-76.147679</td>\n",
       "      <td>-76.980813</td>\n",
       "      <td>-78.181095</td>\n",
       "      <td>-74.369569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.846637</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>286.250000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>63.228982</td>\n",
       "      <td>84.691423</td>\n",
       "      <td>89.798190</td>\n",
       "      <td>99.740466</td>\n",
       "      <td>111.404030</td>\n",
       "      <td>104.664291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4012.253328</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>3298.773719</td>\n",
       "      <td>3100.791967</td>\n",
       "      <td>2580.401323</td>\n",
       "      <td>2244.036432</td>\n",
       "      <td>1999.242370</td>\n",
       "      <td>1852.640349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           off_day    promo_day        sales    dayofweek   dayofmonth  \\\n",
       "count  1268.000000  1268.000000  1268.000000  1268.000000  1268.000000   \n",
       "mean      0.016562     0.127760     6.463512     3.002366    15.835174   \n",
       "std       0.127672     0.333954   392.648113     2.001774     8.801438   \n",
       "min       0.000000     0.000000  -797.642367     0.000000     1.000000   \n",
       "25%       0.000000     0.000000  -182.014248     1.000000     8.000000   \n",
       "50%       0.000000     0.000000   -76.457893     3.000000    16.000000   \n",
       "75%       0.000000     0.000000    50.846637     5.000000    23.000000   \n",
       "max       1.000000     1.000000  4012.253328     6.000000    31.000000   \n",
       "\n",
       "         dayofyear   weekofyear        month      quarter         year  \\\n",
       "count  1268.000000  1268.000000  1268.000000  1268.000000  1268.000000   \n",
       "mean    191.515773    27.887224     6.792587     2.598580  2018.827287   \n",
       "std     108.689397    15.518832     3.556118     1.139337     1.044086   \n",
       "min       1.000000     1.000000     1.000000     1.000000  2017.000000   \n",
       "25%      96.000000    14.000000     4.000000     2.000000  2018.000000   \n",
       "50%     201.500000    29.000000     7.000000     3.000000  2019.000000   \n",
       "75%     286.250000    41.000000    10.000000     4.000000  2020.000000   \n",
       "max     366.000000    53.000000    12.000000     4.000000  2021.000000   \n",
       "\n",
       "       rolling_mean_2  rolling_mean_3  rolling_mean_4  rolling_mean_5  \\\n",
       "count     1268.000000     1268.000000     1268.000000     1268.000000   \n",
       "mean         5.932806        5.532582        5.236885        4.988671   \n",
       "std        366.189085      348.306515      332.858127      320.236176   \n",
       "min       -746.432061     -697.223656     -633.517260     -597.246105   \n",
       "25%       -178.065022     -171.861408     -169.020787     -161.825946   \n",
       "50%        -73.052742      -73.659816      -76.147679      -76.980813   \n",
       "75%         63.228982       84.691423       89.798190       99.740466   \n",
       "max       3298.773719     3100.791967     2580.401323     2244.036432   \n",
       "\n",
       "       rolling_mean_6  rolling_mean_7  \n",
       "count     1268.000000     1268.000000  \n",
       "mean         4.769183        4.559066  \n",
       "std        309.933254      301.469081  \n",
       "min       -563.522146     -538.397212  \n",
       "25%       -155.808104     -155.055750  \n",
       "50%        -78.181095      -74.369569  \n",
       "75%        111.404030      104.664291  \n",
       "max       1999.242370     1852.640349  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sales\"].tail(7) - forecaster.last_window\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing stores 307222...\n",
      "processing stores 307244...\n",
      "processing stores 307248...\n",
      "processing stores 320264...\n",
      "processing stores 328165...\n",
      "processing stores 349920...\n",
      "processing stores 349924...\n",
      "processing stores 349952...\n",
      "processing stores 349958...\n",
      "processing stores 349962...\n",
      "processing stores 349972...\n",
      "processing stores 349978...\n",
      "processing stores 349980...\n",
      "processing stores 349998...\n",
      "processing stores 350016...\n",
      "processing stores 350018...\n",
      "processing stores 350026...\n",
      "processing stores 350028...\n",
      "processing stores 350040...\n",
      "processing stores 350046...\n",
      "processing stores 350054...\n",
      "processing stores 350056...\n",
      "processing stores 350060...\n",
      "processing stores 354468...\n",
      "processing stores 387240...\n",
      "processing stores 412585...\n",
      "processing stores 441997...\n",
      "processing stores 452387...\n",
      "processing stores 461349...\n",
      "processing stores 464495...\n",
      "processing stores 471477...\n",
      "processing stores 476061...\n",
      "processing stores 480733...\n",
      "processing stores 528854...\n",
      "processing stores 536898...\n",
      "processing stores 536902...\n",
      "processing stores 566790...\n",
      "processing stores 566792...\n"
     ]
    }
   ],
   "source": [
    "all_stores_result_CV = []\n",
    "rolls = 4\n",
    "for store in df_store[\"store_id\"].unique():\n",
    "    # for store in df_store[\"store_id\"].unique()[:4]:\n",
    "    # print(f\"processing stores {store}...\")\n",
    "    model_name = \"store_\" + str(store)\n",
    "\n",
    "    # data\n",
    "    ts_1_store = df_store[df_store[\"store_id\"] == store].set_index(\"date\")[\"sales\"]\n",
    "    df_1_store_pro, transformer = preprocessing(\n",
    "        ts_1_store, df_exog, horizon=horizon * rolls\n",
    "    )\n",
    "\n",
    "    # CV\n",
    "    cv_score = cross_validation_result(\n",
    "        df_1_store_pro, forecaster, model_name, transformer, horizon\n",
    "    )\n",
    "\n",
    "    # result\n",
    "    all_stores_result_CV.append(cv_score)\n",
    "all_stores_result_CV = pd.DataFrame(all_stores_result_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_stores_result_CV.to_pickle('results/f8/RF_result_14.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizon = 21\n",
    "## tune on company data\n",
    "grid search\n",
    "- fit once per param set on train set\n",
    "- predict & score on test set (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████| 1/1 [1:29:36<00:00, 5376.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6 7] \n",
      "  Parameters: {'randomforestregressor__max_depth': 50, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 200}\n",
      "  Backtesting metric: 0.3078443142480022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 21\n",
    "\n",
    "# data\n",
    "df, transformer = preprocessing(ts_company, df_exog, horizon)\n",
    "\n",
    "# Grid search hyperparameters and lags\n",
    "from sklearn.preprocessing import Normalizer\n",
    "pipe = make_pipeline(\n",
    "    Normalizer(), \n",
    "    RandomForestRegressor(random_state=123)\n",
    "    )\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=pipe, \n",
    "    lags=10  # This value will be replaced in the grid search\n",
    "    )\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'randomforestregressor__max_depth': [100, 10, 50, 100],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt'],\n",
    "    'randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestregressor__min_samples_split': [2, 5, 10],\n",
    "    'randomforestregressor__n_estimators': [800, 200, 800, 2000]\n",
    "    }\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [7]\n",
    "\n",
    "# Grid search\n",
    "results_grid = grid_search_forecaster(\n",
    "    y=df[\"sales\"],\n",
    "    initial_train_size=len(df) - horizon,\n",
    "    exog=df[df.columns.difference([\"sales\"])],\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=horizon,\n",
    "    refit=True,\n",
    "    metric=\"mean_absolute_percentage_error\",\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/f8/RF_forecaster_21.py']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "# Save model\n",
    "dump(forecaster, filename='results/f8/RF_forecaster_21.py')\n",
    "\n",
    "# Load model\n",
    "# forecaster = load('results/f8/RF_forecaster_21.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores_result_CV = []\n",
    "rolls = 4\n",
    "for store in df_store[\"store_id\"].unique():\n",
    "    # for store in df_store[\"store_id\"].unique()[:4]:\n",
    "    # print(f\"processing stores {store}...\")\n",
    "    model_name = \"store_\" + str(store)\n",
    "\n",
    "    # data\n",
    "    ts_1_store = df_store[df_store[\"store_id\"] == store].set_index(\"date\")[\"sales\"]\n",
    "    df_1_store_pro, transformer = preprocessing(\n",
    "        ts_1_store, df_exog, horizon=horizon * rolls\n",
    "    )\n",
    "\n",
    "    # CV\n",
    "    cv_score = cross_validation_result(\n",
    "        df_1_store_pro, forecaster, model_name, transformer, horizon\n",
    "    )\n",
    "\n",
    "    # result\n",
    "    all_stores_result_CV.append(cv_score)\n",
    "all_stores_result_CV = pd.DataFrame(all_stores_result_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores_result_CV.to_pickle('results/f8/RF_result_21.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizon = 28\n",
    "## tune on company data\n",
    "grid search\n",
    "- fit once per param set on train set\n",
    "- predict & score on test set (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|█████████████████████████████████████| 1/1 [48:27<00:00, 2907.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6 7] \n",
      "  Parameters: {'randomforestregressor__max_depth': 50, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 4, 'randomforestregressor__min_samples_split': 10, 'randomforestregressor__n_estimators': 200}\n",
      "  Backtesting metric: 0.6319211028337506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 28\n",
    "\n",
    "# data\n",
    "df, transformer = preprocessing(ts_company, df_exog, horizon)\n",
    "\n",
    "# Grid search hyperparameters and lags\n",
    "from sklearn.preprocessing import Normalizer\n",
    "pipe = make_pipeline(\n",
    "    Normalizer(), \n",
    "    RandomForestRegressor(random_state=123)\n",
    "    )\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=pipe, \n",
    "    lags=10  # This value will be replaced in the grid search\n",
    "    )\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'randomforestregressor__max_depth': [100, 10, 50, 100],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt'],\n",
    "    'randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestregressor__min_samples_split': [2, 5, 10],\n",
    "    'randomforestregressor__n_estimators': [800, 200, 800, 2000]\n",
    "    }\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [7]\n",
    "\n",
    "# Grid search\n",
    "results_grid = grid_search_forecaster(\n",
    "    y=df[\"sales\"],\n",
    "    initial_train_size=len(df) - horizon,\n",
    "    exog=df[df.columns.difference([\"sales\"])],\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=horizon,\n",
    "    refit=True,\n",
    "    metric=\"mean_absolute_percentage_error\",\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/f8/RF_forecaster_28.py']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "# Save model\n",
    "dump(forecaster, filename='results/f8/RF_forecaster_28.py')\n",
    "\n",
    "# Load model\n",
    "# forecaster = load('results/f8/RF_forecaster_28.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores_result_CV = []\n",
    "rolls = 4\n",
    "for store in df_store[\"store_id\"].unique():\n",
    "    # for store in df_store[\"store_id\"].unique()[:4]:\n",
    "    # print(f\"processing stores {store}...\")\n",
    "    model_name = \"store_\" + str(store)\n",
    "\n",
    "    # data\n",
    "    ts_1_store = df_store[df_store[\"store_id\"] == store].set_index(\"date\")[\"sales\"]\n",
    "    df_1_store_pro, transformer = preprocessing(\n",
    "        ts_1_store, df_exog, horizon=horizon * rolls\n",
    "    )\n",
    "\n",
    "    # CV\n",
    "    cv_score = cross_validation_result(\n",
    "        df_1_store_pro, forecaster, model_name, transformer, horizon\n",
    "    )\n",
    "\n",
    "    # result\n",
    "    all_stores_result_CV.append(cv_score)\n",
    "all_stores_result_CV = pd.DataFrame(all_stores_result_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores_result_CV.to_pickle('results/f8/RF_result_28.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
