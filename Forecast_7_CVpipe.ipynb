{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_scaled_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from pmdarima.preprocessing import FourierFeaturizer\n",
    "from pmdarima import auto_arima, ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "import time\n",
    "import datetime\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_ARIMA(ts, ts_holiday, split=True, yearly_seasonality=True, steps_ahead=30):\n",
    "    '''\n",
    "    split: to split into train and test set\n",
    "    '''\n",
    "    print(f'Preprocessing timeseries data with {steps_ahead} steps ahead')\n",
    "    ts = ts['sales']/1e6\n",
    "    ts.index.freq = 'D'\n",
    "    # yearly seasonality\n",
    "    if yearly_seasonality:\n",
    "        fouri_terms = FourierFeaturizer(365.25, 2)\n",
    "        y_prime, df_fouri = fouri_terms.fit_transform(ts)\n",
    "        df_fouri.index = y_prime.index\n",
    "    # combine exog. variables\n",
    "    df_exog = pd.concat([df_fouri, ts_holiday], axis=1)\n",
    "    df_exog['holiday'] = df_exog['holiday'].fillna(False).astype('int')\n",
    "    df_exog.dropna(inplace=True)\n",
    "    if split:\n",
    "        # split\n",
    "        y_train = y_prime.iloc[:-steps_ahead]\n",
    "        y_test = y_prime.iloc[-steps_ahead:]\n",
    "        exog_train = df_exog.iloc[:-steps_ahead]\n",
    "        exog_test = df_exog.iloc[-steps_ahead:]\n",
    "        return {'y_train':y_train,\n",
    "                'y_test':y_test,\n",
    "                'exog_train':exog_train,\n",
    "                'exog_test':exog_test}\n",
    "    else:\n",
    "        return {'y':y_prime, 'exog': df_exog}\n",
    "\n",
    "def preprocessing_prophet(ts, ts_holiday, steps_ahead=30, split = True):\n",
    "    fb_df = ts[['sales']]\n",
    "    fb_df['sales'] = ts['sales']/1e6\n",
    "    #fb_df['holiday'] = fb_df['holiday'].fillna(False).astype('bool')\n",
    "    fb_df = fb_df.reset_index().rename({'date': 'ds', 'sales': 'y'}, axis=1)\n",
    "    if split:\n",
    "        fb_train = fb_df.iloc[:-steps_ahead]\n",
    "        fb_test = fb_df.iloc[-steps_ahead:]\n",
    "        return {'y_train':fb_train,\n",
    "                'y_test':fb_test}\n",
    "    else:\n",
    "        return fb_df\n",
    "\n",
    "def holidays_ts_prophet(promotion = True, holiday_neg=False):\n",
    "    holiday = pd.DataFrame(holidays.Vietnam(years=[2018, 2019, 2020, 2021]).items()).rename({0:'date', 1:'holiday_neg'}, axis=1)\n",
    "    # Add Tet promotion\n",
    "    promo = pd.DataFrame(holiday[holiday.holiday_neg == 'Vietnamese New Year'].date - datetime.timedelta(days=1))\n",
    "    promo['promotion'] = \"1 days before Tet Holiday\"\n",
    "    # Add Black Friday\n",
    "    promo = promo.append(\n",
    "                pd.DataFrame({'date':[datetime.date(2020,11,27), \n",
    "                                      datetime.date(2019,11,29),\n",
    "                                      datetime.date(2018,11,23)],\n",
    "                              'promotion':[\"Black Friday\",\"Black Friday\",\"Black Friday\"]}))\n",
    "    # set to 1 if holiday affect sales negatively\n",
    "    holiday_off = holiday.replace({\n",
    "            'Vietnamese New Year.*': 1, \n",
    "             '.*day of Tet Holiday': 1,\n",
    "             'International Labor Day': 1,\n",
    "             '\\D': np.NaN}, \n",
    "            regex=True).dropna()\n",
    "    if promotion:\n",
    "        promotions = pd.DataFrame({\n",
    "                'holiday':'big_promotion',\n",
    "                'ds':promo.date,\n",
    "                'lower_window': -14, # 2 weeks before\n",
    "                'upper_window': 0})\n",
    "    else:\n",
    "        promotions = None\n",
    "    if holiday_neg:\n",
    "        holiday_negative = pd.DataFrame({\n",
    "                'holiday':'holiday_off',\n",
    "                'ds':holiday_off.date,\n",
    "                'lower_window': 0,\n",
    "                'upper_window': 0})\n",
    "    else:\n",
    "        holiday_negative = None\n",
    "    return pd.concat((promotions, holiday_negative))\n",
    "\n",
    "def auto_arima_model(y_train, exog_train, diff_num):\n",
    "    time_start = time.time()\n",
    "    print('start auto arima...')\n",
    "    # Fit model to the level to find common order\n",
    "    arima_model = auto_arima(\n",
    "        y=y_train,\n",
    "        exogenous=exog_train,\n",
    "        D=diff_num, \n",
    "        seasonal=True, m=7 # Weekly seasonality\n",
    "    )\n",
    "    time_stop = time.time()\n",
    "    print(f'finished auto arima, model: {arima_model}, total time: {round(time_stop-time_start)} sec')\n",
    "    return arima_model\n",
    "\n",
    "def cross_validation_prophet(prophet_data, param_grid, steps_ahead = 30):\n",
    "    cv_prophet_result = pd.DataFrame(columns=['params','mape','rmse'])\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    for params in all_params:\n",
    "        # set up model\n",
    "        prophet_model = Prophet(**params\n",
    "                                ).add_seasonality(name='weekly', period=7, fourier_order=5, prior_scale=10\n",
    "                                ).add_seasonality(name='yearly', period=365.25, fourier_order=5, prior_scale=1)\n",
    "        #m.add_regressor('holiday')\n",
    "        prophet_model.fit(prophet_data['y_train'])\n",
    "        # set up CV\n",
    "        df_cv = cross_validation(prophet_model, initial=(str(prophet_data['y_train'].shape[0]-steps_ahead*2)+' days'), period='7 days', horizon='30 days', parallel=\"processes\")\n",
    "        # evaluate\n",
    "        df_p = performance_metrics(df_cv)\n",
    "        cv_prophet_result = cv_prophet_result.append({'params':params, \n",
    "                                            'mape'  :df_p['mape'].values[-1],\n",
    "                                            'rmse'  :df_p['rmse'].values[-1]}, ignore_index=True)\n",
    "    return cv_prophet_result\n",
    "\n",
    "\n",
    "def cross_validation_result(data, model_name, model, rolls=4, horizon=30, prophet_params=None):\n",
    "    '''\n",
    "    '''\n",
    "    cv_score = []\n",
    "    for i in range(rolls):\n",
    "        if model_name=='arima':\n",
    "            model.fit(y=data['y'].iloc[:-(rolls-i)*horizon], \n",
    "                      X=data['exog'].iloc[:-(rolls-i)*horizon])\n",
    "            y_hat = model.predict(n_periods=horizon, \n",
    "                                  exogenous=data['exog'].iloc[np.r_[-(rolls-i)*horizon:-(rolls-i-1)*horizon]])\n",
    "            y_test = data['y'].iloc[np.r_[-(rolls-i)*horizon:-(rolls-i-1)*horizon]]\n",
    "            mape_OOS = round(mean_absolute_percentage_error(y_test, y_hat), 3)\n",
    "        elif model_name=='prophet':\n",
    "            model = Prophet(**prophet_params\n",
    "                           ).add_seasonality(name='weekly', period=7, fourier_order=5, prior_scale=10\n",
    "                           ).add_seasonality(name='yearly', period=365.25, fourier_order=5, prior_scale=1)\n",
    "            model.fit(data.iloc[:-(rolls-i)*horizon,:])\n",
    "            y_hat=model.predict(data.iloc[np.r_[-(rolls-i)*horizon:-(rolls-i-1)*horizon],:])['yhat']\n",
    "            y_test = data['y'].iloc[np.r_[-(rolls-i)*horizon:-(rolls-i-1)*horizon]]\n",
    "            mape_OOS = round(mean_absolute_percentage_error(y_test, y_hat), 3)\n",
    "        cv_score.append(mape_OOS)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store = pd.read_pickle('data/df_daily.pkl')\n",
    "# holiday\n",
    "ts_holiday = pd.read_pickle('data/holiday.pkl')\n",
    "#print(ts_holiday.index)\n",
    "df_company = df_store.groupby('date').sum()[['sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_run = ['arima','prophet']\n",
    "steps_ahead=30\n",
    "prophet_holidays=holidays_ts_prophet(promotion=True, holiday_neg=True)\n",
    "param_grid_prophet = {\n",
    "    'changepoint_prior_scale': [0.01, 0.1, 1, 10,20],\n",
    "    'changepoint_range': [0.8, 0.9],\n",
    "    'holidays_prior_scale':[0.1, 1],\n",
    "    'seasonality_mode': ['additive'],\n",
    "    'holidays':[prophet_holidays],\n",
    "    'daily_seasonality': [False],\n",
    "    'weekly_seasonality': [False],\n",
    "    'yearly_seasonality': [False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross-validation for arima models\n",
      "Preprocessing timeseries data with 30 steps ahead\n",
      "start auto arima...\n",
      "finished auto arima, model:  ARIMA(4,0,0)(2,1,0)[7]          , total time: 143 sec\n",
      "Preprocessing timeseries data with 30 steps ahead\n",
      "Finished cross-validation, total time: 158 sec\n",
      "Start cross-validation for prophet models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228E03D0AC0>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228D5C638E0>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000229365AB460>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228E032B070>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228C3396F10>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228E032B0D0>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228E032BFA0>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228899B4850>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x0000022942B82D00>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228D5C638E0>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x000002296A066FA0>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228E0357100>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000229365AB460>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x0000022942B824C0>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228E03D0160>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228E032BF40>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x000002295FBA23A0>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228D5C17280>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228C33C6B80>\n",
      "INFO:prophet:Making 5 forecasts with cutoffs between 2020-11-04 00:00:00 and 2020-12-02 00:00:00\n",
      "INFO:prophet:Applying in parallel with <concurrent.futures.process.ProcessPoolExecutor object at 0x00000228E032B0D0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cross-validation, total time: 407 sec\n"
     ]
    }
   ],
   "source": [
    "cv_pipe_result = {}\n",
    "best_model = {}\n",
    "for model_name in models_to_run:\n",
    "    if model_name =='arima':\n",
    "        print(f'Start cross-validation for {model_name} models')\n",
    "        time_start = time.time()\n",
    "        data = preprocessing_ARIMA(ts=df_company, ts_holiday=ts_holiday, split=True, yearly_seasonality=True, steps_ahead=steps_ahead)\n",
    "        arima_model = auto_arima_model(y_train=data['y_train'], exog_train=data['exog_train'], diff_num=1)\n",
    "        # now get the data for cross-validatio and start the process\n",
    "        data = preprocessing_ARIMA(ts=df_company, ts_holiday=ts_holiday, split=False, yearly_seasonality=True, steps_ahead=steps_ahead) \n",
    "        cv_score = cross_validation_result(data=data, model_name=model_name, model=arima_model, rolls=4, horizon=steps_ahead)\n",
    "        # save result\n",
    "        cv_pipe_result[model_name] = cv_score\n",
    "        best_model[model_name] = arima_model\n",
    "        time_stop = time.time()\n",
    "        print(f'Finished cross-validation, total time: {round(time_stop-time_start)} sec')\n",
    "    if model_name =='prophet':\n",
    "        print(f'Start cross-validation for {model_name} models')\n",
    "        time_start = time.time()\n",
    "        data = preprocessing_prophet(ts=df_company, ts_holiday=prophet_holidays, steps_ahead=steps_ahead,split=True)\n",
    "        cv_prophet_result = cross_validation_prophet(prophet_data=data, \n",
    "                                                     param_grid=param_grid_prophet,                                                       \n",
    "                                                     steps_ahead = steps_ahead) \n",
    "        prophet_params = cv_prophet_result.sort_values('mape').iloc[0,0]\n",
    "        # now get the data for cross-validatio and start the process\n",
    "        data = preprocessing_prophet(ts=df_company, ts_holiday=prophet_holidays, steps_ahead=steps_ahead,split=False)\n",
    "        cv_score = cross_validation_result(data=data, model_name=model_name, model=None, rolls=4, horizon=steps_ahead, prophet_params=prophet_params)\n",
    "        # save result\n",
    "        cv_pipe_result[model_name] = cv_score\n",
    "        best_model[model_name] = prophet_params\n",
    "        time_stop = time.time()\n",
    "        print(f'Finished cross-validation, total time: {round(time_stop-time_start)} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arima': [0.338, 0.428, 0.448, 0.202], 'prophet': [0.15, 0.442, 0.282, 0.266]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pipe_result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc1c8500d1c7d68ad4fe3470dd61d80ea8045d933e624a9aa39b7580cf077167"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DataMining_Lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
