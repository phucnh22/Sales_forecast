{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    mean_absolute_scaled_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(y, X, horizon):\n",
    "    y.index.freq='D'\n",
    "\n",
    "    # split\n",
    "    y_train, y_test = train_test_split(y, test_size=horizon, shuffle=False)\n",
    "\n",
    "    # transform (deseasonalize)\n",
    "    transformer = make_pipeline(Deseasonalizer(sp=7), Detrender())\n",
    "    y_train_trans = transformer.fit_transform(y_train)\n",
    "    y_train_trans.name = y.name\n",
    "    y_test_trans = transformer.transform(y_test)\n",
    "    y_test_trans.name = y.name\n",
    "    y_trans = pd.concat([y_train_trans, y_test_trans])\n",
    "\n",
    "    # join\n",
    "    df = X.join(y_trans).dropna()\n",
    "    \n",
    "    # extract exo. variables from date index\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['weekofyear'] = df.index.isocalendar()['week']\n",
    "    df['month'] = df.index.month\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['year'] = df.index.year\n",
    "\n",
    "    # rolling mean\n",
    "    df['rolling_mean_2'] = df['sales'].rolling(2).mean()\n",
    "    df['rolling_mean_3'] = df['sales'].rolling(3).mean()\n",
    "    df['rolling_mean_4'] = df['sales'].rolling(4).mean()\n",
    "    df['rolling_mean_5'] = df['sales'].rolling(5).mean()\n",
    "    df['rolling_mean_6'] = df['sales'].rolling(6).mean()\n",
    "    df['rolling_mean_7'] = df['sales'].rolling(7).mean()\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df, transformer\n",
    "\n",
    "\n",
    "# CV \n",
    "def cross_validation_result(data, tuned_model, model_name, transformer, horizon, rolls):\n",
    "    # score model with CV on store data\n",
    "    mae_CVs = []\n",
    "    rmse_CVs = []\n",
    "    mape_CVs = []\n",
    "    mase_CVs = []\n",
    "    for i in range(rolls):\n",
    "        # print(f\"fold {i}---------------\")\n",
    "        \n",
    "        # split data\n",
    "        y_train = data.iloc[: -(rolls - i) * horizon]\n",
    "        y_test = data.iloc[\n",
    "            np.r_[-(rolls - i) * horizon : -(rolls - i - 1) * horizon]]\n",
    "\n",
    "        # fit model\n",
    "        model = tuned_model\n",
    "        model.fit(\n",
    "            y    = y_train['sales'],\n",
    "            exog = y_train[y_train.columns.difference(['sales'])]\n",
    "        )\n",
    "        \n",
    "        # make forecast\n",
    "        y_hat = model.predict(\n",
    "                        steps = horizon,\n",
    "                        exog = y_test[y_test.columns.difference(['sales'])]\n",
    "                    )\n",
    "        y_hat = pd.Series(data=y_hat, index=y_test.index)\n",
    "        \n",
    "        # inverse\n",
    "        y_train = transformer.inverse_transform(y_train['sales'])\n",
    "        y_test = transformer.inverse_transform(y_test['sales'])\n",
    "        y_hat = transformer.inverse_transform(y_hat)\n",
    "                \n",
    "        # score\n",
    "        mae_CVs.append(round(mean_absolute_error(y_test, y_hat), 3))\n",
    "        rmse_CVs.append(round(mean_squared_error(y_test, y_hat, square_root=True), 3))\n",
    "        mape_CVs.append(round(mean_absolute_percentage_error(y_test, y_hat), 3))\n",
    "        mase_CVs.append(round(mean_absolute_scaled_error(y_test, y_hat, y_train=y_train), 3))\n",
    "        \n",
    "    return {'store':model_name,\n",
    "        'mae_XGB':np.mean(mae_CVs),\n",
    "        'rmse_XGB':np.mean(rmse_CVs),\n",
    "        'mape_XGB':np.mean(mape_CVs),\n",
    "        'mase_XGB':np.mean(mase_CVs),\n",
    "        'fc_XGB':y_hat,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store = pd.read_pickle(\"data/df_daily.pkl\")\n",
    "df_store['sales'] = df_store['sales']/1e6\n",
    "df_exog = pd.read_pickle(\"data/df_exog.pkl\")\n",
    "ts_company = df_store.groupby(\"date\").sum()[\"sales\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizon = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune on company data\n",
    "grid search:\n",
    "- fit once per param set on train set\n",
    "- predict & score on test set (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 7\n",
    "\n",
    "# Grid search hyperparameter and lags\n",
    "# ==============================================================================\n",
    "pipe = make_pipeline(Normalizer(), XGBRegressor(random_state=123))\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=pipe, lags=10  # This value will be replaced in the grid search\n",
    ")\n",
    "\n",
    "# Regressor hyperparameters\n",
    "# param_grid = {\n",
    "#     \"xgbregressor__n_estimators\": [50],\n",
    "#     \"xgbregressor__max_depth\": [5],\n",
    "# } \n",
    "param_grid = {\n",
    "    \"xgbregressor__max_depth\": [3, 10, 20],\n",
    "    \"xgbregressor__learning_rate\": [0.01, 0.1, 0.3],\n",
    "    \"xgbregressor__subsample\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__colsample_bytree\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__colsample_bylevel\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__n_estimators\": [100, 500, 1000],\n",
    "}\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [list(range(horizon, horizon*2))]\n",
    "\n",
    "# Prepare data\n",
    "df, transformer = preprocessing(ts_company, df_exog, horizon)\n",
    "\n",
    "# Grid search\n",
    "results_grid = grid_search_forecaster(\n",
    "    y=df[\"sales\"],\n",
    "    initial_train_size=len(df) - horizon,\n",
    "    exog=df[df.columns.difference([\"sales\"])],\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=horizon,\n",
    "    refit=True,\n",
    "    metric=\"mean_absolute_percentage_error\",\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "# Save model\n",
    "dump(forecaster, filename='results/f81/XGB_forecaster_7.py')\n",
    "\n",
    "# Load model\n",
    "forecaster = load('results/f81/XGB_forecaster_7.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolls = 4\n",
    "all_stores_result_CV = []\n",
    "\n",
    "for store in df_store[\"store_id\"].unique():\n",
    "    # for store in df_store[\"store_id\"].unique()[:4]:\n",
    "    print(f\"\\nprocessing stores {store}...\")\n",
    "    model_name = \"store_\" + str(store)\n",
    "\n",
    "    # data\n",
    "    ts_1_store = df_store[df_store[\"store_id\"] == store].set_index(\"date\")[\"sales\"]\n",
    "    df_1_store_pro, transformer = preprocessing(\n",
    "        ts_1_store, \n",
    "        df_exog, \n",
    "        horizon=horizon * rolls\n",
    "    )\n",
    "\n",
    "    # CV\n",
    "    cv_score = cross_validation_result(\n",
    "        df_1_store_pro, \n",
    "        forecaster, \n",
    "        model_name, \n",
    "        transformer,\n",
    "        horizon,\n",
    "        rolls\n",
    "    )\n",
    "\n",
    "    # result\n",
    "    all_stores_result_CV.append(cv_score)\n",
    "all_stores_result_CV = pd.DataFrame(all_stores_result_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores_result_CV.to_pickle('results/f81/XGB_result_7.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizon = 14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune on company data\n",
    "grid search:\n",
    "- fit once per param set on train set\n",
    "- predict & score on test set (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 14\n",
    "\n",
    "# Grid search hyperparameter and lags\n",
    "# ==============================================================================\n",
    "pipe = make_pipeline(Normalizer(), XGBRegressor(random_state=123))\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=pipe, lags=10  # This value will be replaced in the grid search\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbregressor__max_depth\": [3, 10, 20],\n",
    "    \"xgbregressor__learning_rate\": [0.01, 0.1, 0.3],\n",
    "    \"xgbregressor__subsample\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__colsample_bytree\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__colsample_bylevel\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__n_estimators\": [100, 500, 1000],\n",
    "}\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [list(range(horizon, horizon*2))]\n",
    "\n",
    "# Prepare data\n",
    "df, transformer = preprocessing(ts_company, df_exog, horizon)\n",
    "\n",
    "# Grid search\n",
    "results_grid = grid_search_forecaster(\n",
    "    y=df[\"sales\"],\n",
    "    initial_train_size=len(df) - horizon,\n",
    "    exog=df[df.columns.difference([\"sales\"])],\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=horizon,\n",
    "    refit=True,\n",
    "    metric=\"mean_absolute_percentage_error\",\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "# Save model\n",
    "dump(forecaster, filename='results/f81/XGB_forecaster_14.py')\n",
    "\n",
    "# Load model\n",
    "forecaster = load('results/f81/XGB_forecaster_14.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolls = 4\n",
    "all_stores_result_CV = []\n",
    "\n",
    "for store in df_store[\"store_id\"].unique():\n",
    "    # for store in df_store[\"store_id\"].unique()[:4]:\n",
    "    # print(f\"\\nprocessing stores {store}...\")\n",
    "    model_name = \"store_\" + str(store)\n",
    "\n",
    "    # data\n",
    "    ts_1_store = df_store[df_store[\"store_id\"] == store].set_index(\"date\")[\"sales\"]\n",
    "    df_1_store_pro, transformer = preprocessing(\n",
    "        ts_1_store, \n",
    "        df_exog, \n",
    "        horizon=horizon * rolls\n",
    "    )\n",
    "\n",
    "    # CV\n",
    "    cv_score = cross_validation_result(\n",
    "        df_1_store_pro, \n",
    "        forecaster, \n",
    "        model_name, \n",
    "        transformer,\n",
    "        horizon,\n",
    "        rolls\n",
    "    )\n",
    "\n",
    "    # result\n",
    "    all_stores_result_CV.append(cv_score)\n",
    "all_stores_result_CV = pd.DataFrame(all_stores_result_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores_result_CV.to_pickle('results/f81/XGB_result_14.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizon = 21\n",
    "\n",
    "## tune on company data\n",
    "grid search:\n",
    "- fit once per param set on train set\n",
    "- predict & score on test set (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 21\n",
    "\n",
    "# Grid search hyperparameter and lags\n",
    "# ==============================================================================\n",
    "pipe = make_pipeline(Normalizer(), XGBRegressor(random_state=123))\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=pipe, lags=10  # This value will be replaced in the grid search\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbregressor__max_depth\": [3, 10, 20],\n",
    "    \"xgbregressor__learning_rate\": [0.01, 0.1, 0.3],\n",
    "    \"xgbregressor__subsample\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__colsample_bytree\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__colsample_bylevel\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__n_estimators\": [100, 500, 1000],\n",
    "}\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [list(range(horizon, horizon*2))]\n",
    "\n",
    "# Prepare data\n",
    "df, transformer = preprocessing(ts_company, df_exog, horizon)\n",
    "\n",
    "# Grid search\n",
    "results_grid = grid_search_forecaster(\n",
    "    y=df[\"sales\"],\n",
    "    initial_train_size=len(df) - horizon,\n",
    "    exog=df[df.columns.difference([\"sales\"])],\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=horizon,\n",
    "    refit=True,\n",
    "    metric=\"mean_absolute_percentage_error\",\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "# Save model\n",
    "dump(forecaster, filename='results/f81/XGB_forecaster_21.py')\n",
    "\n",
    "# # Load model\n",
    "forecaster = load('results/f81/XGB_forecaster_21.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolls = 4\n",
    "all_stores_result_CV = []\n",
    "\n",
    "for store in df_store[\"store_id\"].unique():\n",
    "    # for store in df_store[\"store_id\"].unique()[:4]:\n",
    "    # print(f\"\\nprocessing stores {store}...\")\n",
    "    model_name = \"store_\" + str(store)\n",
    "\n",
    "    # data\n",
    "    ts_1_store = df_store[df_store[\"store_id\"] == store].set_index(\"date\")[\"sales\"]\n",
    "    df_1_store_pro, transformer = preprocessing(\n",
    "        ts_1_store, \n",
    "        df_exog, \n",
    "        horizon=horizon * rolls\n",
    "    )\n",
    "\n",
    "    # CV\n",
    "    cv_score = cross_validation_result(\n",
    "        df_1_store_pro, \n",
    "        forecaster, \n",
    "        model_name, \n",
    "        transformer,\n",
    "        horizon,\n",
    "        rolls\n",
    "    )\n",
    "\n",
    "    # result\n",
    "    all_stores_result_CV.append(cv_score)\n",
    "all_stores_result_CV = pd.DataFrame(all_stores_result_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores_result_CV.to_pickle('results/f81/XGB_result_21.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizon = 28\n",
    "\n",
    "## tune on company data\n",
    "grid search:\n",
    "- fit once per param set on train set\n",
    "- predict & score on test set (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 28\n",
    "\n",
    "# Grid search hyperparameter and lags\n",
    "# ==============================================================================\n",
    "pipe = make_pipeline(Normalizer(), XGBRegressor(random_state=123))\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=pipe, lags=10  # This value will be replaced in the grid search\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbregressor__max_depth\": [3, 10, 20],\n",
    "    \"xgbregressor__learning_rate\": [0.01, 0.1, 0.3],\n",
    "    \"xgbregressor__subsample\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__colsample_bytree\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__colsample_bylevel\": [0.5, 0.7, 1.0],\n",
    "    \"xgbregressor__n_estimators\": [100, 500, 1000],\n",
    "}\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [list(range(horizon, horizon*2))]\n",
    "\n",
    "# Prepare data\n",
    "df, transformer = preprocessing(ts_company, df_exog, horizon)\n",
    "\n",
    "# Grid search\n",
    "results_grid = grid_search_forecaster(\n",
    "    y=df[\"sales\"],\n",
    "    initial_train_size=len(df) - horizon,\n",
    "    exog=df[df.columns.difference([\"sales\"])],\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=horizon,\n",
    "    refit=True,\n",
    "    metric=\"mean_absolute_percentage_error\",\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "# Save model\n",
    "dump(forecaster, filename='results/f81/XGB_forecaster_28.py')\n",
    "\n",
    "# # Load model\n",
    "forecaster = load('results/f81/XGB_forecaster_28.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolls = 4\n",
    "all_stores_result_CV = []\n",
    "\n",
    "for store in df_store[\"store_id\"].unique():\n",
    "    # for store in df_store[\"store_id\"].unique()[:4]:\n",
    "    # print(f\"\\nprocessing stores {store}...\")\n",
    "    model_name = \"store_\" + str(store)\n",
    "\n",
    "    # data\n",
    "    ts_1_store = df_store[df_store[\"store_id\"] == store].set_index(\"date\")[\"sales\"]\n",
    "    df_1_store_pro, transformer = preprocessing(\n",
    "        ts_1_store, \n",
    "        df_exog, \n",
    "        horizon=horizon * rolls\n",
    "    )\n",
    "\n",
    "    # CV\n",
    "    cv_score = cross_validation_result(\n",
    "        df_1_store_pro, \n",
    "        forecaster, \n",
    "        model_name, \n",
    "        transformer,\n",
    "        horizon,\n",
    "        rolls\n",
    "    )\n",
    "\n",
    "    # result\n",
    "    all_stores_result_CV.append(cv_score)\n",
    "all_stores_result_CV = pd.DataFrame(all_stores_result_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores_result_CV.to_pickle('results/f81/XGB_result_28.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
